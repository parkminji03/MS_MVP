import requests, os, json
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv()

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPEN_AI_KEY"),
    api_version="2024-12-01-preview",
    azure_endpoint=os.getenv("AZURE_OPEN_AI_URL")
)

AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX = os.getenv("AZURE_SEARCH_INDEX", "survey-responses")

# âœ… RAG ì‘ë‹µ
def rag_answer(question, passages, model="gpt-4.1-mini"):
    # passagesê°€ dict ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë³´ì¥
    safe_passages = []
    for p in passages:
        if isinstance(p, dict):
            safe_passages.append(p)
        else:
            safe_passages.append({"column": "", "sentiment": "", "text": str(p)})

    context = "\n".join(
        [f"- [{p.get('column','')}] ({p.get('sentiment','')}): {p.get('text','')}" for p in safe_passages]
    )

    prompt = f"""
    ë‹¹ì‹ ì€ êµìœ¡ ì„¤ë¬¸ ë°ì´í„°ì— ê¸°ë°˜í•´ ë‹µë³€í•´ì£¼ëŠ” AIì…ë‹ˆë‹¤.
    ì•„ë˜ ì»¨í…ìŠ¤íŠ¸(ì‘ë‹µ)ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µì„ í•´ì£¼ì„¸ìš”.
    ì§ì ‘ì ì¸ ë‹µì´ ì—†ë”ë¼ë„ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆìœ¼ë©´ ê·¸ì— ê¸°ë°˜í•´ ì¶”ë¡ í•´ì„œ ë‹µë³€í•˜ì„¸ìš”. 
    ì§ˆë¬¸ì´ ê¸¸ê±°ë‚˜ ë³µì¡í•˜ë”ë¼ë„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ë‚´ê³ , ê·¸ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì‘ë‹µì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    ê·¼ê±°ëŠ” ë°˜ë“œì‹œ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.

    ì»¨í…ìŠ¤íŠ¸:
    {context}

    ì§ˆë¬¸ :
    {question}
    """

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# âœ… ì„¤ë¬¸ì‘ë‹µ csvë¥¼ ì¸ë±ìŠ¤ ë¬¸ì„œì— ì—…ë¡œë“œ
def index_documents_to_search(docs):
    url = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX}/docs/index?api-version=2024-05-01-preview"
    headers = {"Content-Type": "application/json", "api-key": os.getenv("AZURE_SEARCH_API_KEY")}
    all_responses = []

    for i in range(0, len(docs), 10):  # 10ê°œì”© ì—…ë¡œë“œ
        batch = docs[i:i+10]
        payload = {"value": [{"@search.action": "mergeOrUpload", **doc} for doc in batch]}
        r = requests.post(url, headers=headers, data=json.dumps(payload))
        all_responses.append((r.status_code, r.text))

        if r.status_code != 200:
            print(f"âŒ ì¸ë±ì‹± ì‹¤íŒ¨ (batch {i//10 + 1}):", r.status_code, r.text)
        else:
            print(f"âœ… ì¸ë±ì‹± ì„±ê³µ (batch {i//10 + 1})")

    return all_responses

# ìƒˆë¡œìš´ íŒŒì¼ì´ ì—…ë¡œë“œ ë ë•Œë§ˆë‹¤ index í´ë¦¬ì–´ 
def clear_index():
    url_index = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX}/docs/index?api-version=2024-05-01-preview"
    url_search = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX}/docs/search?api-version=2024-05-01-preview"
    headers = {"Content-Type": "application/json", "api-key": os.getenv("AZURE_SEARCH_API_KEY")}

    total_deleted = 0

    while True:
        # 1. ì „ì²´ ë¬¸ì„œ id ì¡°íšŒ (1000ê°œì”©)
        r = requests.post(
            url_search,
            headers=headers,
            data=json.dumps({"search": "*", "select": "id", "top": 1000})
        )
        if r.status_code != 200:
            print("âŒ ì „ì²´ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨:", r.status_code, r.text)
            break

        data = r.json()
        ids = [doc["id"] for doc in data.get("value", []) if "id" in doc]

        if not ids:
            break  # ë” ì´ìƒ ì‚­ì œí•  ë¬¸ì„œ ì—†ìŒ

        # 2. delete ìš”ì²­
        payload = {"value": [{"@search.action": "delete", "id": i} for i in ids]}
        r2 = requests.post(url_index, headers=headers, data=json.dumps(payload))

        if r2.status_code == 200:
            total_deleted += len(ids)
            print(f"âœ… {len(ids)}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ (ëˆ„ì  {total_deleted})")
        else:
            print("âŒ ì‚­ì œ ì‹¤íŒ¨:", r2.status_code, r2.text)
            break

    print(f"ğŸ”„ ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ, ì´ {total_deleted}ê°œ ë¬¸ì„œ ì‚­ì œë¨")

# âœ… ì»¬ëŸ¼ í›„ë³´ ìë™ ì¶”ì¶œ
def get_available_columns(top=100):
    url = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX}/docs/search?api-version=2024-05-01-preview"
    headers = {"Content-Type": "application/json", "api-key": os.getenv("AZURE_SEARCH_API_KEY")}
    payload = {
        "search": "*",
        "select": "column",
        "top": top
    }
    r = requests.post(url, headers=headers, data=json.dumps(payload))
    if r.status_code == 200:
        data = r.json()
        columns = {doc.get("column") for doc in data.get("value", []) if "column" in doc}
        return list(columns)
    else:
        print("ì»¬ëŸ¼ ì¶”ì¶œ ì‹¤íŒ¨:", r.status_code, r.text)
        return []

# âœ… ì§ˆë¬¸ â†’ ì»¬ëŸ¼ ìë™ ë§¤í•‘
def pick_best_columns(question: str, available_columns: list, model="gpt-4.1-mini"):
    prompt = f"""
    ë‹¹ì‹ ì€ ì„¤ë¬¸ ë¶„ì„ ë„ìš°ë¯¸ ì…ë‹ˆë‹¤..
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì•„ë˜ ì»¬ëŸ¼ ì¤‘ ì–´ë–¤ ê²ƒë“¤ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ ëª¨ë‘ ê³¨ë¼ì£¼ì„¸ìš”.
    ë‹¨ì–´ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ê¹Œìš´ ì»¬ëŸ¼ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
    ì˜ˆ: ì§ˆë¬¸ì— 'êµì¬'ë¼ê³  í•˜ë©´ 'êµì¬í‰ê°€' ì»¬ëŸ¼ì„ ì„ íƒí•´ì•¼ í•´.
    ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥í•˜ë©°, ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³  ë‹µí•´.

    ì§ˆë¬¸: {question}
    ì»¬ëŸ¼ í›„ë³´: {", ".join(available_columns)}
    """
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    raw = response.choices[0].message.content.strip()
    if raw == "ì—†ìŒ":
        return []
    return [c.strip() for c in raw.split(",") if c.strip()]

# âœ… RAGìš© ê´€ë ¨ ì‘ë‹µ ì¶”ì¶œ (ìë™ ì»¬ëŸ¼ ë§¤í•‘ í¬í•¨)
def semantic_search_responses(query, top=8, model="gpt-4.1-mini"):
    print("semantic_search_responses í˜¸ì¶œë¨")
    available_columns = get_available_columns()
    best_columns = [c for c in pick_best_columns(query, available_columns, model=model)
                    if c in available_columns]
    print("ğŸ“Œ ì§ˆë¬¸:", query)
    print("ğŸ“Œ ì»¬ëŸ¼ í›„ë³´:", available_columns)
    print("ğŸ“Œ ì„ íƒëœ ì»¬ëŸ¼:", best_columns)

    url = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX}/docs/search?api-version=2024-05-01-preview"
    headers = {"Content-Type": "application/json", "api-key": os.getenv("AZURE_SEARCH_API_KEY")}
    passages = []
    seen = set()

    # ì„ íƒëœ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ê°ê° ê²€ìƒ‰
    if best_columns:
        for col in best_columns:
            payload = {
                "search": "*",
                "top": top,
                "queryType": "semantic",
                "semanticConfiguration": "default",
                "filter": f"column eq '{col}'",
                "queryLanguage": "ko-KR"
            }
            r = requests.post(url, headers=headers, data=json.dumps(payload))
            if r.status_code == 200:
                data = r.json()
                for doc in data.get("value", []):
                    text = doc.get("text", "")
                    if text not in seen:
                        seen.add(text)
                        passages.append({
                            "column": doc.get("column", ""),
                            "sentiment": doc.get("sentiment", ""),
                            "text": text
                        })
    else:
        # ì»¬ëŸ¼ ë§¤í•‘ ì‹¤íŒ¨ â†’ ì „ì²´ ê²€ìƒ‰ fallback
        print("âš fallback")
        payload = {"search": query, "top": top, "queryType": "semantic", "semanticConfiguration": "default","queryLanguage": "ko-KR"}
        r = requests.post(url, headers=headers, data=json.dumps(payload))
        if r.status_code == 200:
            data = r.json()
            for doc in data.get("value", []):
                text = doc.get("text", "")
                if text not in seen:
                    seen.add(text)
                    passages.append({
                        "column": doc.get("column", ""),
                        "sentiment": doc.get("sentiment", ""),
                        "text": text
                    })
    print("ğŸ“Œ ê²€ìƒ‰ payload:", payload)
    print("ğŸ“Œ ê²€ìƒ‰ ì‘ë‹µ:", r.status_code, r.text[:500])
    return passages
